{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/awiksshiithnarang/movie-review-sentiment-analysis?scriptVersionId=136627159\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Importing required libraries:**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nimport logging\n\nlogging.getLogger( \"tensorflow\" ).setLevel( logging.ERROR )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T14:09:36.425668Z","iopub.execute_input":"2023-07-12T14:09:36.426079Z","iopub.status.idle":"2023-07-12T14:09:55.255093Z","shell.execute_reply.started":"2023-07-12T14:09:36.426051Z","shell.execute_reply":"2023-07-12T14:09:55.253888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the required dataset and preparing the data:**","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv( \"/kaggle/input/imdb-movie-ratings-sentiment-analysis/movie.csv\" )\nreviews = dataset[ \"text\" ].tolist()\nsentiments = dataset[ \"label\" ].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T14:10:00.593458Z","iopub.execute_input":"2023-07-12T14:10:00.594143Z","iopub.status.idle":"2023-07-12T14:10:01.874316Z","shell.execute_reply.started":"2023-07-12T14:10:00.594112Z","shell.execute_reply":"2023-07-12T14:10:01.873358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Subwording, tokenization & padding the reviews and splitting the data:**","metadata":{}},{"cell_type":"code","source":"vocab_size = 500\nembedding_size = 16\nmax_length = 50\ntokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus( reviews, vocab_size, max_subword_length = 5 )\nfor i, review in enumerate( reviews ):\n    reviews[ i ] = tokenizer.encode( review )\npadded_reviews = tf.keras.preprocessing.sequence.pad_sequences( reviews, maxlen = max_length, padding = \"post\", truncating = \"post\" )\ntraining_size = int( len( reviews ) * 0.8 )\ntraining_reviews = padded_reviews[ 0 : training_size ]\ntraining_sentiments = sentiments[ 0 : training_size ]\nvalidation_reviews = padded_reviews[ training_size : ]\nvalidation_sentiments = sentiments[ training_size : ]\ntraining_sentiments = np.array( training_sentiments )\nvalidation_sentiments = np.array( validation_sentiments )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T14:10:15.968798Z","iopub.execute_input":"2023-07-12T14:10:15.969155Z","iopub.status.idle":"2023-07-12T14:13:28.339359Z","shell.execute_reply.started":"2023-07-12T14:10:15.969125Z","shell.execute_reply":"2023-07-12T14:13:28.33837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating, compiling, training different models:**","metadata":{}},{"cell_type":"code","source":"plain_model = tf.keras.Sequential( [ tf.keras.layers.Embedding( vocab_size, embedding_size, input_length = max_length ), tf.keras.layers.Dropout( 0.5 ), tf.keras.layers.GlobalAveragePooling1D(), tf.keras.layers.Dense( 6, activation = \"relu\" ), tf.keras.layers.Dense( 1, activation = \"sigmoid\" ) ] )\nplain_model.compile( loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [ \"accuracy\" ] )\nprint( plain_model.summary() )\ntf.keras.backend.clear_session()\nepochs = 100\nearly_stopping = tf.keras.callbacks.EarlyStopping( patience = 50 )\nplain_history = plain_model.fit( training_reviews, training_sentiments, epochs = epochs, validation_data = ( validation_reviews, validation_sentiments ), callbacks = [ early_stopping ] )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T15:55:38.595549Z","iopub.execute_input":"2023-07-12T15:55:38.59591Z","iopub.status.idle":"2023-07-12T16:03:01.44759Z","shell.execute_reply.started":"2023-07-12T15:55:38.595882Z","shell.execute_reply":"2023-07-12T16:03:01.446446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = tf.keras.Sequential( [ tf.keras.layers.Embedding( vocab_size, embedding_size, input_length = max_length ), tf.keras.layers.Conv1D( 128, 5, activation = \"relu\" ), tf.keras.layers.Dropout( 0.5 ), tf.keras.layers.GlobalMaxPooling1D(), tf.keras.layers.Dense( 6, activation = \"relu\" ), tf.keras.layers.Dense( 1, activation = \"sigmoid\" ) ] )\ncnn_model.compile( loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [ \"accuracy\" ] )\nprint( cnn_model.summary() )\ntf.keras.backend.clear_session()\nepochs = 100\nearly_stopping = tf.keras.callbacks.EarlyStopping( patience = 50 )\ncnn_history = cnn_model.fit( training_reviews, training_sentiments, epochs = epochs, validation_data = ( validation_reviews, validation_sentiments ), callbacks = [ early_stopping ] )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T16:04:04.591351Z","iopub.execute_input":"2023-07-12T16:04:04.591724Z","iopub.status.idle":"2023-07-12T16:09:15.859729Z","shell.execute_reply.started":"2023-07-12T16:04:04.591694Z","shell.execute_reply":"2023-07-12T16:09:15.858766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gru_model = tf.keras.Sequential( [ tf.keras.layers.Embedding( vocab_size, embedding_size, input_length = max_length ), tf.keras.layers.Bidirectional( tf.keras.layers.GRU( embedding_size ) ), tf.keras.layers.Dropout( 0.5 ), tf.keras.layers.Dense( 6, activation = \"relu\" ), tf.keras.layers.Dense( 1, activation = \"sigmoid\" ) ] )\ngru_model.compile( loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [ \"accuracy\" ] )\nprint( gru_model.summary() )\ntf.keras.backend.clear_session()\nepochs = 100\nearly_stopping = tf.keras.callbacks.EarlyStopping( patience = 50 )\ngru_history = gru_model.fit( training_reviews, training_sentiments, epochs = epochs, validation_data = ( validation_reviews, validation_sentiments ), callbacks = [ early_stopping ] )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T16:11:01.631489Z","iopub.execute_input":"2023-07-12T16:11:01.632058Z","iopub.status.idle":"2023-07-12T16:22:08.34809Z","shell.execute_reply.started":"2023-07-12T16:11:01.632017Z","shell.execute_reply":"2023-07-12T16:22:08.347066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model = tf.keras.Sequential( [ tf.keras.layers.Embedding( vocab_size, embedding_size, input_length = max_length ), tf.keras.layers.Bidirectional( tf.keras.layers.LSTM( embedding_size ) ), tf.keras.layers.Dropout( 0.5 ), tf.keras.layers.Dense( 6, activation = \"relu\" ), tf.keras.layers.Dense( 1, activation = \"sigmoid\" ) ] )\nlstm_model.compile( loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [ \"accuracy\" ] )\nprint( lstm_model.summary() )\ntf.keras.backend.clear_session()\nepochs = 100\nearly_stopping = tf.keras.callbacks.EarlyStopping( patience = 50 )\nlstm_history = lstm_model.fit( training_reviews, training_sentiments, epochs = epochs, validation_data = ( validation_reviews, validation_sentiments ), callbacks = [ early_stopping ] )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T16:22:44.895436Z","iopub.execute_input":"2023-07-12T16:22:44.895793Z","iopub.status.idle":"2023-07-12T16:33:24.52373Z","shell.execute_reply.started":"2023-07-12T16:22:44.895764Z","shell.execute_reply":"2023-07-12T16:33:24.522644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_lstm_model = tf.keras.Sequential( [ tf.keras.layers.Embedding( vocab_size, embedding_size, input_length = max_length ), tf.keras.layers.Bidirectional( tf.keras.layers.LSTM( embedding_size, return_sequences = True ) ),  tf.keras.layers.Bidirectional( tf.keras.layers.LSTM( embedding_size ) ), tf.keras.layers.Dropout( 0.5 ), tf.keras.layers.Dense( 6, activation = \"relu\" ), tf.keras.layers.Dense( 1, activation = \"sigmoid\" ) ] )\nstacked_lstm_model.compile( loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [ \"accuracy\" ] )\nprint( stacked_lstm_model.summary() )\ntf.keras.backend.clear_session()\nepochs = 100\nearly_stopping = tf.keras.callbacks.EarlyStopping( patience = 50 )\nstacked_lstm_history = stacked_lstm_model.fit( training_reviews, training_sentiments, epochs = epochs, validation_data = ( validation_reviews, validation_sentiments ), callbacks = [ early_stopping ] )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T16:40:00.216001Z","iopub.execute_input":"2023-07-12T16:40:00.216417Z","iopub.status.idle":"2023-07-12T16:57:12.195271Z","shell.execute_reply.started":"2023-07-12T16:40:00.216385Z","shell.execute_reply":"2023-07-12T16:57:12.193951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comparing models used:**","metadata":{}},{"cell_type":"code","source":"def plot_graphs( history, epochs ):\n    acc = history.history[ \"accuracy\" ]\n    val_acc = history.history[ \"val_accuracy\" ]\n    loss = history.history[ \"loss\" ]\n    val_loss = history.history[ \"val_loss\" ]\n    plt.figure( figsize = ( 8, 8 ) )\n    plt.subplot( 1, 2, 1 )\n    plt.plot( epochs, acc, label = \"Training accuracy\" )\n    plt.plot( epochs, val_acc, label = \"Validation accuracy\" )\n    plt.legend( loc = \"lower right\" )\n    plt.subplot( 1, 2, 2 )\n    plt.plot( epochs, loss, label = \"Training loss\" )\n    plt.plot( epochs, val_loss, label = \"Validation loss\" )\n    plt.legend( loc = \"upper right\" )\n    \nplot_graphs( plain_history, range( 1, 101 ) )\nplot_graphs( cnn_history, range( 1, 65 ) )\nplot_graphs( gru_history, range( 1, 68 ) )\nplot_graphs( lstm_history, range( 1, 65 ) )\nplot_graphs( stacked_lstm_history, range( 1, 66 ) )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T17:11:51.204544Z","iopub.execute_input":"2023-07-12T17:11:51.204914Z","iopub.status.idle":"2023-07-12T17:11:53.281385Z","shell.execute_reply.started":"2023-07-12T17:11:51.204885Z","shell.execute_reply":"2023-07-12T17:11:53.280179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predictions of sentiments for new reviews:**","metadata":{}},{"cell_type":"code","source":"review1 = \"I loved this movie\"\nreview2 = \"that was the worst movie I've ever seen\"\nreview3 = \"too much violence even for a Bond film\"\nreview4 = \"a captivating recounting of a cherished myth\"\nreview5 = \"I saw this movie yesterday and I was feeling low to start with, but it was such a wonderful movie that it lifted my spirits and brightened my day, you can\\'t go wrong with a movie with Whoopi Goldberg in it.\"\nreview6 = \"I don\\'t understand why it received an oscar recommendation for best movie, it was long and boring\"\nreview7 = \"the scenery was magnificent, the CGI of the dogs was so realistic I thought they were played by real dogs even though they talked!\"\nreview8 = \"The ending was so sad and yet so uplifting at the same time. I'm looking for an excuse to see it again\"\nreview9 = \"I had expected so much more from a movie made by the director who made my most favorite movie ever, I was very disappointed in the tedious story\"\nreview10 = \"I wish I could watch this movie every day for the rest of my life\"\nnew_reviews = [review1, review2, review3, review4, review5, review6, review7, \n               review8, review9, review10]\n\ndef predict_and_print( model, reviews ):\n    tkn_in_fn = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus( reviews, 500, max_subword_length = 5 )\n    for i, review in enumerate( reviews ):\n        reviews[ i ] = tkn_in_fn.encode( review )\n    padded_reviews = tf.keras.preprocessing.sequence.pad_sequences( reviews, maxlen = 50, padding = \"post\", truncating = \"post\" )\n    predictions = model.predict( padded_reviews )\n    return predictions\n\nprint( \"On comparing all the above models that we've trained, the model which contains CNN is the best.\" )\nprint( \"So, we'll use this for our predictions.\" )\nprint( \"----------\" )\nfor i, review in enumerate( new_reviews ):\n    print( \"Review {}: {}\".format( ( i + 1 ), review ) )\npreds = predict_and_print( cnn_model, new_reviews )\nfor i, pred in enumerate( preds ):\n    print( \"Prediction of sentiment of review {}: {}\".format( ( i + 1 ), pred ) )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T18:35:34.832418Z","iopub.execute_input":"2023-07-12T18:35:34.832826Z","iopub.status.idle":"2023-07-12T18:35:35.015224Z","shell.execute_reply.started":"2023-07-12T18:35:34.832796Z","shell.execute_reply":"2023-07-12T18:35:35.013584Z"},"trusted":true},"execution_count":null,"outputs":[]}]}